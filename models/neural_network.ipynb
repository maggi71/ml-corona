{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung und Vergleich von Machine Learning und Deep Learning Algorithmen zur Vorhersage von COVID-19 Kennzahlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronale Netze\n",
    "Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from disk\n",
    "# X_train = np.load('../preprocessing/X_train.npy')\n",
    "# X_test = np.load('../preprocessing/X_test.npy')\n",
    "# y_train = np.load('../preprocessing/y_train.npy')\n",
    "# y_test = np.load('../preprocessing/y_test.npy')\n",
    "\n",
    "data = np.load('../preprocessing/dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move first columns (= cases) to the end of the array\n",
    "permutations = [1,2,3,4,5,6,7,8,9,10,0]\n",
    "data = data[:, permutations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform data into sequences\n",
    "def transform_to_sequences(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t# n_vars corresponds to the number of features\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t\n",
    "\t# input sequence (t-n, ..., t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t\t\n",
    "\t# forecast sequence(t, t+1, ..., t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t\t\n",
    "\t# put all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t\n",
    "\tif dropnan:\n",
    "\t\t# drop all rows that contains Nan values (1st row)\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 11)\n",
      "(199, 11)\n"
     ]
    }
   ],
   "source": [
    "# Split data in training and test set\n",
    "num_datapoints = data.shape[0]\n",
    "num_training = int(num_datapoints*0.7)\n",
    "\n",
    "train, test = data[:num_training], data[num_training:]\n",
    "\n",
    "# Verify the shapes of train and test\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the datasets using RobutScaler (as this scaler scales the data according to the quantile range (default: Inter Quartile Range IQR))\n",
    "# TODO: select good scaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data into sequences\n",
    "train_transformed = transform_to_sequences(train_scaled, 14, 1)\n",
    "test_transformed = transform_to_sequences(test_scaled, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 165)\n",
      "(185, 165)\n"
     ]
    }
   ],
   "source": [
    "# Verify the shapes of train_transformed and test_transformed\n",
    "print(train_transformed.shape)\n",
    "print(test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in input X and output y\n",
    "n_input_timestamps = 14\n",
    "n_features_per_timestamp = 11\n",
    "n_input_features = n_input_timestamps * n_features_per_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 154)\n",
      "(448, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train_transformed.values[:, :n_input_features], train_transformed.values[:, n_input_features:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272483</td>\n",
       "      <td>0.115409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299731</td>\n",
       "      <td>0.126950</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.019874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326979</td>\n",
       "      <td>0.138491</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.031571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354228</td>\n",
       "      <td>0.150032</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.033853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381476</td>\n",
       "      <td>0.161573</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.040890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6         7         8         9         10\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.272483  0.115409  0.000000  0.018068\n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.299731  0.126950  0.018519  0.019874\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.326979  0.138491  0.027778  0.031571\n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.354228  0.150032  0.037037  0.033853\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.381476  0.161573  0.027778  0.040890"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 0 to 9 as we just want to predict feature #10 (= cases)\n",
    "y_train = y_train[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 154)\n",
      "(185, 11)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_transformed.values[:, :n_input_features], test_transformed.values[:, n_input_features:]\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867587</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.733161</td>\n",
       "      <td>0.474988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.435694</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>0.133835</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.850201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859001</td>\n",
       "      <td>0.599870</td>\n",
       "      <td>0.311022</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.592891</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.129780</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.013778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884554</td>\n",
       "      <td>0.493402</td>\n",
       "      <td>0.183680</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.490748</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.122248</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.010452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.805378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939504</td>\n",
       "      <td>0.270029</td>\n",
       "      <td>0.202176</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.263427</td>\n",
       "      <td>0.203448</td>\n",
       "      <td>0.103708</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.007760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.007126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.867587  0.000014  0.733161  0.474988  1.000000  0.000371  0.435694   \n",
       "1  0.850201  0.000000  0.859001  0.599870  0.311022  0.000604  0.592891   \n",
       "2  0.806728  0.000000  0.884554  0.493402  0.183680  0.000868  0.490748   \n",
       "3  0.805378  0.000000  0.939504  0.270029  0.202176  0.001949  0.263427   \n",
       "4  0.755921  0.000000  0.929662  1.000000  0.247540  0.002303  1.000000   \n",
       "\n",
       "         7         8        9         10  \n",
       "0  0.248276  0.133835  0.00000  0.021300  \n",
       "1  0.241379  0.129780  0.03125  0.013778  \n",
       "2  0.206897  0.122248  0.12500  0.010452  \n",
       "3  0.203448  0.103708  0.09375  0.007760  \n",
       "4  0.200000  0.095017  0.09375  0.007126  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 0 to 9 as we just want to predict feature #10 (= cases)\n",
    "y_test = y_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to fit into the LSTM model (dimension must be [samples, time steps, features])\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], n_input_timestamps, n_features_per_timestamp))\n",
    "y_train_lstm = y_train.reshape((y_train.shape[0], 1))\n",
    "\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], n_input_timestamps, n_features_per_timestamp))\n",
    "y_test_lstm = y_test.reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to fit into CNN model (dimension must be [samples, time steps, features])\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], n_input_timestamps, n_features_per_timestamp))\n",
    "y_train_cnn = y_train.reshape((y_train.shape[0], 1))\n",
    "\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], n_input_timestamps, n_features_per_timestamp))\n",
    "y_test_cnn = y_test.reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neuronal Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation is based on https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/\n",
    "def create_cnn_model(n_filters, n_kernel, activation_conv, pool_size, activation_dense, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation=activation_conv, input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2])))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation=activation_dense))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 13, 64)            1472      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 6, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 5, 64)             8256      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 2, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                6450      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,229\n",
      "Trainable params: 16,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn = create_cnn_model()\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network (mit LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation is based on https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "def create_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 100)               44800     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,901\n",
      "Trainable params: 44,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = create_lstm_model()\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierung der Hyperparameter\n",
    "Neuronale Netzwerke verfügen über mehrere Hyperparameter (z.B. Anzahl der Layer, Anzahl der Neuronen pro Layer, Aktivierungsfunktion, Optimizer, Batch Size, etc.), die massgeblich die Performance eines Modells beeinflussen können. Aus diesem Grund gilt es diese zu optimieren. Dazu wird oft 'Grid Search' verwendet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierung des CNN\n",
    "\n",
    "Folgende Hyperparameter werden für das CNN optimiert:\n",
    "- n_filters: Anzahl der Filter (z.B. 32)\n",
    "- n_kernel: Grösse der Filter\n",
    "- n_epochs: Anzahl Trainings-Epochen\n",
    "- n_batch: Grösse des Mini-Batches (z.B. 32)\n",
    "- pool_size: Grösse des Pooling Fensters\n",
    "- activation_conv: Aktivierungsfunktion des Convolution Layers\n",
    "- activation_dense: Aktivierungsfunktion des Dense Layers\n",
    "- optimizer: Optimierungsfunktion des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_configs():\n",
    "    n_filter = [32, 64, 128, 256]\n",
    "    n_kernel = [2, 3, 5, 7]\n",
    "    n_epoches = [100, 200, 300, 500, 1000]\n",
    "    n_batch = [16, 32, 64, 128, 256]\n",
    "    pool_size = [2]\n",
    "    activation_conv = ['relu', 'tanh']\n",
    "    activation_dense = ['relu', 'tanh']\n",
    "    optimizer = ['sgd', 'adam', 'rmsprop', 'adagrad', 'adamax', 'adadelta']\n",
    "\n",
    "    configs = list()\n",
    "    for a in n_filter:\n",
    "        for b in n_kernel:\n",
    "            for c in n_epoches:\n",
    "                for d in n_batch:\n",
    "                    for e in pool_size:\n",
    "                        for f in activation_conv:\n",
    "                            for g in activation_dense:\n",
    "                                for h in optimizer:\n",
    "                                    cfg = [a,b,c,d,e,f,g,h]\n",
    "                                    configs.append(cfg)\n",
    "    \n",
    "    print('Number of configs: %d' % len(configs))\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_parameters(config):\n",
    "    # Unpack the config\n",
    "    n_filters, n_kernel, n_epochs, n_batch, pool_size, activation_conv, activation_dense, optimizer = config\n",
    "\n",
    "    # Build the model\n",
    "    model = create_cnn_model(n_filters, n_kernel, activation_conv, pool_size, activation_dense, optimizer)\n",
    "\n",
    "    # Perform cross validation\n",
    "    scores = []\n",
    "    splits = TimeSeriesSplit(n_splits=5)\n",
    "    for train_index, val_index in splits.split(X_train_cnn):\n",
    "        X_tr, X_val = X_train_cnn[train_index], X_train_cnn[val_index]\n",
    "        y_tr, y_val = y_train_cnn[train_index], y_train_cnn[val_index]\n",
    "\n",
    "        history = model.fit(X_tr, y_tr, epochs=n_epochs, batch_size=n_batch, shuffle=False)\n",
    "        score = model.evaluate(X_val, y_val, verbose=0)\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Calculate mean of the scores\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of configs: 9600\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0023\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0013\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0012\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0010\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.8510e-04\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.6782e-04\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.5077e-04\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.3414e-04\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.1796e-04\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0211e-04\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.8659e-04\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.7170e-04\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.5722e-04\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.4313e-04\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2928e-04\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1555e-04\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.0205e-04\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.8861e-04\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.7481e-04\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6133e-04\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.4840e-04\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.3615e-04\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2429e-04\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1273e-04\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.0136e-04\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.8954e-04\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.7812e-04\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6727e-04\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5666e-04\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.4636e-04\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.3630e-04\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.2637e-04\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.1644e-04\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0678e-04\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.9755e-04\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.8865e-04\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7956e-04\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.7094e-04\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.6267e-04\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.5451e-04\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4660e-04\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.3903e-04\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3185e-04\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.2493e-04\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1827e-04\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1110e-04\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.0413e-04\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9753e-04\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9112e-04\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8503e-04\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7952e-04\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.7458e-04\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6982e-04\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6536e-04\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.6114e-04\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.5710e-04\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.5324e-04\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4954e-04\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4598e-04\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4287e-04\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/xmycd40d1fddjh8_1bmnc4dr0000gn/T/ipykernel_2686/1583236705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w5/xmycd40d1fddjh8_1bmnc4dr0000gn/T/ipykernel_2686/3711049558.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "model_configs = get_model_configs()\n",
    "\n",
    "scores = []\n",
    "for cfg in model_configs:\n",
    "    score = optimize_parameters(cfg)\n",
    "    scores.append(score)\n",
    "\n",
    "# Find top 5 scores\n",
    "sorted(range(len(scores)), key=lambda i: scores[i])[-5:]\n",
    "\n",
    "# Find corresponding config for top score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training der Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training des CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0522\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0190\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0110\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0098\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0072\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0066\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0073\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0087\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0112\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0069\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0038\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0046\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0038\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0033\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0035\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0074\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0036\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0038\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0037\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0023\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.5957e-04\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.4814e-04\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.7905e-04\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.5468e-04\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.3416e-04\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.7678e-04\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.2167e-04\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.0991e-04\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.9103e-04\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.4242e-04\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 9.6791e-04\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.0859e-04\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.8429e-04\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.4391e-04\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.4206e-04\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.1814e-04\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.1463e-04\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.2493e-04\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.4472e-04\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.8738e-04\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.0813e-04\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.1580e-04\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.5875e-04\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.0479e-04\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.8225e-04\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.4405e-04\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.2789e-04\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.0453e-04\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.2223e-04\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.1594e-04\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.1537e-04\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.5482e-04\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.4670e-04\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.4934e-04\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.6065e-04\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0020\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0048\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0040\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.2397e-04\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.9876e-04\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.2329e-04\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.1822e-04\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.5435e-04\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 5.0888e-04\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.6177e-04\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.4935e-04\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.2352e-04\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.1322e-04\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.8869e-04\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.7334e-04\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.7214e-04\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.7725e-04\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.0724e-04\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.1004e-04\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.0298e-04\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.3933e-04\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 5.6493e-04\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.4304e-04\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 8.0739e-04\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.4660e-04\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.9984e-04\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.4005e-04\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.7110e-04\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.7961e-04\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.1257e-04\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.7532e-04\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.4394e-04\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 2.9936e-04\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.0259e-04\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.1527e-04\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 5.3618e-04\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 7.1724e-04\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 5.5160e-04\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.7641e-04\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.9291e-04\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.3113e-04\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 8.0948e-04\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 9.5631e-04\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.3411e-04\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0018\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.1820e-04\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.3248e-04\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.6682e-04\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.7882e-04\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.0366e-04\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.5024e-04\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.5446e-04\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.9608e-04\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.8808e-04\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.8045e-04\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.0594e-04\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2.9460e-04\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 2.5663e-04\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2.4601e-04\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 2.2239e-04\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 2.0883e-04\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 2.0017e-04\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.9833e-04\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2.1308e-04\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2.2288e-04\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 2.4462e-04\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2.2741e-04\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2.1071e-04\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 2.3672e-04\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.3248e-04\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.0402e-04\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.1009e-04\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.2166e-04\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.1169e-04\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 2.7459e-04\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.6060e-04\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.1165e-04\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 9.5765e-04\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 7.3760e-04\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 6.9752e-04\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.6740e-04\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.5295e-04\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.1979e-04\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.6197e-04\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.1396e-04\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 5.7990e-04\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 4.7748e-04\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 5.4948e-04\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 5.0264e-04\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.8240e-04\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.2757e-04\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 9.3840e-04\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 8.6555e-04\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "# Train CNN model\n",
    "history_cnn = model_cnn.fit(X_train_cnn, y_train_cnn, epochs=300, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "pyplot.plot(history_cnn.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training des LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "14/14 [==============================] - 1s 5ms/step - loss: 0.0255\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0231\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0121\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0095\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0099\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0090\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0096\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0170\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0241\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0122\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0080\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0073\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0067\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0067\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0062\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0060\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0061\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0073\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0106\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0102\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0106\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0072\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0064\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0065\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0060\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0058\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0057\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0079\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0085\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0098\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0077\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0071\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0086\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0047\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0054\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0048\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0037\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0034\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0035\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0041\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0034\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0030\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0030\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0037\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0034\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0035\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0030\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0030\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0030\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0034\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0035\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0034\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0019\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0011\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 9.9945e-04\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0043\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.7723e-04\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.9895e-04\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.7645e-04\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.3702e-04\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.6580e-04\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.9796e-04\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.4172e-04\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.0353e-04\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.9206e-04\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.0276e-04\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.7681e-04\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.5599e-04\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.8960e-04\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.4020e-04\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.1872e-04\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.0041e-04\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.3821e-04\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.9930e-04\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.8722e-04\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.4708e-04\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.5811e-04\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.1194e-04\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.7581e-04\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.4230e-04\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.0338e-04\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.8876e-04\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.4526e-04\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.2996e-04\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3193e-04\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.0366e-04\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.1937e-04\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.2917e-04\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.3171e-04\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.6777e-04\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0017\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.8846e-04\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0013\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.9994e-04\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.6020e-04\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.7145e-04\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 7.3140e-04\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.4025e-04\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.3996e-04\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.5023e-04\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.3927e-04\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM model\n",
    "history_lstm = model_lstm.fit(X_train_lstm, y_train_lstm, epochs=300, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7l0lEQVR4nO2deZhcVZn/P28tXb3vna2zdHYICQQIIciigGDAJSAiccWRGWZGUfwhzuA46owzzoCOjjKCCoIiKqAIEhVEIQkIJCF7SEKWTmfpJUl3et+qu5bz++Peqq6uruqu7vSa+36ep5+6de5S51Ql93vf5bxHjDEoiqIozsM11h1QFEVRxgYVAEVRFIeiAqAoiuJQVAAURVEcigqAoiiKQ/GMdQcGQ3FxsSkrKxvrbiiKokwotm7desoYUxLfPqEEoKysjC1btox1NxRFUSYUInI0Ubu6gBRFURyKCoCiKIpDUQFQFEVxKBMqBqAoijJYAoEAVVVV+P3+se7KiJOens706dPxer0pHa8CoCjKGU1VVRU5OTmUlZUhImPdnRHDGEN9fT1VVVXMnj07pXPUBaQoyhmN3++nqKjojL75A4gIRUVFg7J0VAAURTnjOdNv/hEGO05HCMBjbxzh9ztrxrobiqIo4wpHCMATbx7jD7tUABRFGX2ampp48MEHB33e9ddfT1NT0/B3KIaUBEBEVorIfhEpF5F7Euz3ichT9v5NIlJmt18jIltF5C379aqYc9bb19xh/00atlHFkeXz0NYVHKnLK4qiJCWZAASD/d+Tnn/+efLz80eoVxYDZgGJiBt4ALgGqAI2i8gaY8zemMNuAxqNMfNEZDVwH3ALcAp4vzGmRkQWAy8CpTHnfcwYM+K1HbJ9Hpo6ukf6YxRFUfpwzz33cOjQIZYuXYrX6yU9PZ2CggL27dvHgQMHuOGGG6isrMTv93PnnXdy++23Az2lb9ra2rjuuuu47LLLeOONNygtLeW5554jIyPjtPuWShrocqDcGFMBICJPAquAWAFYBfybvf008AMREWPM9phj9gAZIuIzxnSdds8HQXa6h6rGjtH8SEVRxiH//vs97K1pGdZrLpqWy9fff07S/ffeey+7d+9mx44drF+/nve+973s3r07mqr56KOPUlhYSGdnJxdddBE33XQTRUVFva5x8OBBnnjiCR5++GE+/OEP89vf/paPf/zjp933VFxApUBlzPsqej/F9zrGGBMEmoGiuGNuArbF3fx/art/vipJwtcicruIbBGRLXV1dSl0ty856gJSFGWcsHz58l55+vfffz/nnXceK1asoLKykoMHD/Y5Z/bs2SxduhSACy+8kCNHjgxLX0ZlIpiInIPlFro2pvljxphqEckBfgt8Avh5/LnGmIeAhwCWLVs2pBXss30e2vwqAIridPp7Uh8tsrKyotvr16/npZdeYsOGDWRmZvKud70rYR6/z+eLbrvdbjo7O4elL6lYANXAjJj30+22hMeIiAfIA+rt99OBZ4FPGmMORU4wxlTbr63Ar7BcTSNCls9De3eIUHhI+qEoijJkcnJyaG1tTbivubmZgoICMjMz2bdvHxs3bhzVvqViAWwG5ovIbKwb/Wrgo3HHrAFuBTYAHwLWGmOMiOQDfwTuMca8HjnYFol8Y8wpEfEC7wNeOt3BJCMn3Rpme3eQ3PTUamQoiqIMB0VFRVx66aUsXryYjIwMJk+eHN23cuVKfvSjH3H22WezcOFCVqxYMap9G1AAjDFBEbkDK4PHDTxqjNkjIt8Athhj1gCPAI+LSDnQgCUSAHcA84CvicjX7LZrgXbgRfvm78a6+T88jOPqRbbPFoAuFQBFUUafX/3qVwnbfT4fL7zwQsJ9ET9/cXExu3fvjrbffffdw9avlGIAxpjngefj2r4Ws+0Hbk5w3n8C/5nkshem3s3TI9u2ANr8Qcs5pSiKojhjJnCWbQG0JskEqmzo4ODJxD46RVGUMxVHCECOL8YCSMC9L+zj7qd3jWaXFEUZRYxxRgLIYMfpCAGIuoCSWADt3UE6uzVNVFHORNLT06mvrz/jRSCyHkB6enrK5zhiQZjsASyAYMhoiqiinKFMnz6dqqoqhjqRdCIRWREsVRwhADk+K/MnmQUQDIfR+7+inJl4vd6UV8hyGo5wAWX53EA/AqAWgKIoDsQRAuBxu0j3uvqxAFQAFEVxHo4QAIBsn5fWZDGAcFgFQFEUx+EYAchJT14RNBgyhM7wDAFFUZR4HCMA6V43nd2hhPuCYUNYLQBFURyGYwTA7YJwkqf8UNgQVAFQFMVhOEcARJL6+QOhsFoAiqI4DscIgMsl/VoAGgNQFMVpOEYA+rcANA1UURTn4RgBcLmSC0BI00AVRXEgjhEAtyR3AWkaqKIoTsQ5AtCPBRAMG4xxTslYRVEUcJAAuFxCKMn9PRgOA6gbSFEUR+EYAXALSVM9I3MAdC6AoihOwjkCkMQFFLLdP5B8opiiKMqZiGMEwJUkCBxx/4C6gBRFcRaOEoBEN/hgTGAgRgsURVHOeBwjAG6XJEz1jPX7B1UBFEVxEI4RAJdLEgaBg6EYF5DGABRFcRCOEQC3kHDd31i3kBoAiqI4CccIQLJSEIGYNrUAFEVxEo4RgGSlIEK9gsAqAIqiOAfnCEBSC6DH76MTwRRFcRKOEYBk6wHEioLOA1AUxUk4RgCSrQcQiMkC0pnAiqI4CecIQD+lIBJtK4qinOmkJAAislJE9otIuYjck2C/T0SesvdvEpEyu/0aEdkqIm/Zr1fFnHOh3V4uIveLiAzbqBJglYLo2x4IqQAoiuJMBhQAEXEDDwDXAYuAj4jIorjDbgMajTHzgP8F7rPbTwHvN8YsAW4FHo8554fA3wHz7b+VpzGOAXG7Et/g1QJQFMWppGIBLAfKjTEVxphu4ElgVdwxq4DH7O2ngatFRIwx240xNXb7HiDDthamArnGmI3GWoXl58ANpzuY/nAlKwWhM4EVRXEoqQhAKVAZ877Kbkt4jDEmCDQDRXHH3ARsM8Z02cdXDXBNAETkdhHZIiJb6urqUuhuYtySpBREWOcBKIriTEYlCCwi52C5hf5+sOcaYx4yxiwzxiwrKSkZch+SF4PTeQCKojiTVASgGpgR83663ZbwGBHxAHlAvf1+OvAs8EljzKGY46cPcM1hxSWScN3foM4EVhTFoaQiAJuB+SIyW0TSgNXAmrhj1mAFeQE+BKw1xhgRyQf+CNxjjHk9crAx5jjQIiIr7OyfTwLPnd5Q+sftspKM4gO9Qa0FpCiKQxlQAGyf/h3Ai8DbwK+NMXtE5Bsi8gH7sEeAIhEpB+4CIqmidwDzgK+JyA77b5K97zPAT4By4BDwwnANKhFRAYi3ADQLSFEUh+JJ5SBjzPPA83FtX4vZ9gM3JzjvP4H/THLNLcDiwXT2dHDZ0wziSz73ygJSAVAUxUE4aCaw9aoWgKIoioVjBCBiAfSJAcQGgTUGoCiKg3CMAERiAPGZPrFpoCFdEUxRFAfhOAHo4wKKsQB0UXhFUZyEYwSgJwic3AJQF5CiKE7CMQKQWhroqHZJURRlTHGOAKQSBNYsIEVRHIRjBMDlSjIPIGwSbiuKopzpOEYAks4D0HLQiqI4FMcIQLJ5ACEtB60oikNxnADEZ/rokpCKojgVxwhAsmqgoXAYT5J9iqIoZzKOEYCkFkDYkOaxvgaNASiK4iQcIwDuJFlAoZDBFxEAtQAURXEQDhIA6zX+KT8QDuPzuAENAiuK4iwcIwD9ZQFFXEA6D0BRFCfhGAGIuoASFIPzugURrQWkKIqzcI4AJCsFEQ7jcbnwuERjAIqiOArHCIAr2XoAIYPHLbhENAtIURRH4RgB6K8aqMcluF2iQWBFURyFYwQg6ZKQ4TAetwu3iAaBFUVxFI4RgP6CwG6X4FILQFEUh+EcAYhaAL3bg2ErC8jj0hiAoijOwjEC4IpMBOvjAjK4XS5cLtEVwRRFcRSOEYDkLqAwXpfgFiGki8IriuIgnCMA/cwEdttZQGoBKIriJBwjAK4kFkAgFMbrdllpoBoDUBTFQThGAFKzAFQAFEVxDs4RgCSLvgSiM4G1HLSiKM7CMQKQzAUUipkJrAKgKIqTcIwAJJ8HYM0E1lpAiqI4jZQEQERWish+ESkXkXsS7PeJyFP2/k0iUma3F4nIOhFpE5EfxJ2z3r7mDvtv0rCMKAmuJAvCRGoBedw6E1hRFGfhGegAEXEDDwDXAFXAZhFZY4zZG3PYbUCjMWaeiKwG7gNuAfzAV4HF9l88HzPGbDnNMaRExAJIWA3UpbWAFEVxHqlYAMuBcmNMhTGmG3gSWBV3zCrgMXv7aeBqERFjTLsx5jUsIRhTkgWBLReQXQtIXUCKojiIVASgFKiMeV9ltyU8xhgTBJqBohSu/VPb/fNVEfsRPQ4RuV1EtojIlrq6uhQumZhkQWDLAojMBFYBUBTFOYxlEPhjxpglwOX23ycSHWSMecgYs8wYs6ykpGTIH5ZoHoAxptd6ACoAiqI4iVQEoBqYEfN+ut2W8BgR8QB5QH1/FzXGVNuvrcCvsFxNI0aiBWEiN3yPPRNYBUBRFCeRigBsBuaLyGwRSQNWA2vijlkD3GpvfwhYa0xyh7qIeESk2N72Au8Ddg+284PBlSAIHIwKgG0BaAxAURQHMWAWkDEmKCJ3AC8CbuBRY8weEfkGsMUYswZ4BHhcRMqBBiyRAEBEjgC5QJqI3ABcCxwFXrRv/m7gJeDh4RxYPLYB0GseQFQAXNaawJoGqiiKkxhQAACMMc8Dz8e1fS1m2w/cnOTcsiSXvTC1Lg4PCV1AoYgAuNQCUBTFcThmJrCIIGIFfiME7Pr/ERdQMKQCoCiKc3CMAAB9Uj2jQWCXC49LJ4IpiuIsHCUArjg3T8AOCHhcQk66h1Z/YKy6piiKMuo4SgDccYHeUEwWUF6Gl+ZOFQBFUZyDswQgbtnHgO3zd7ssAfAHwnQFQ2PUO0VRlNHFUQLgkt6lIIJ2ENjrdpGX4QVQK0BRFMfgKAGIn+0bjLEAcm0BaFEBUBTFIaQ0D+BMIT7XP5L143UL6d40AJo6VAAURXEGjrIA4mf7hmwXkNulLiBFUZyHowQg3gUUCQJ77SAwqAAoiuIcHCUA8ev+RsTArQKgKIoDcZQAuF29XUDRiWBuF7npVjhEBUBRFKfgOAGILfcTiqkG6nG7yPZ5VAAURXEMjhIAlxBnAfTMBAas2cCaBaQoikNwlADEB4Fji8EBWg5CURRH4SgBiA8CB2PKQYMKgKIozsJRAhAfBA6GemIAoAKgKIqzcJQApHvd+GOKvfVYANbXkJnmpjOgxeAURXEGjhKAzDQ37V2xAtDbAvB5XXQHwwnPVRRFOdNwlABkpXno6A5G38e7gHweN10qAIqiOARHCUCmL5kFYH0NaR6XrgegKIpjcJQAZPviLYDeWUA+j4uuYLjXwvGKoihnKo4SgMw0T0ILwO3qEQBjeiaIKYqinMk4SgCy0tx0h8LRQG8kBuC1s4B8HjcA3SGNAyiKcubjKAHI9FkF3zq7LSsgsh6AbQDg81pfR5emgiqK4gAcJQDZPusJv92OAwTCBq9bELEUIM22BDQTSFEUJ+AoAchMsyyA9i5LAEJhE/X/Q4wFoAKgKIoDcJQAZEUtAMvFEwiF8bp6voJIDEBTQRVFcQKOEoCIBdARawG4YywAj/V1DOdsYH8gxI9fOUR1Uyf/8PhW6tu6hu3aiqIop4OjBCAr4gKKWgAmOgkMYi2A4ROANTtr+O8X9nHpvWv5054TrN1XO2zXVhRFOR2cJQARF1DUAghHy0CANRMYoCswfAKQmebu9T7HXnpSURRlrElJAERkpYjsF5FyEbknwX6fiDxl798kImV2e5GIrBORNhH5Qdw5F4rIW/Y590skFWcEyfJFLABLAIIhE50FDD0uoOGMAcSLiVYbVRRlvDCgAIiIG3gAuA5YBHxERBbFHXYb0GiMmQf8L3Cf3e4HvgrcneDSPwT+Dphv/60cygAGQ+RpvMOeDRwMm14WQCQLaDhjAPE3/M5uzTBSFGV8kIoFsBwoN8ZUGGO6gSeBVXHHrAIes7efBq4WETHGtBtjXsMSgigiMhXINcZsNFbhnZ8DN5zGOFIimgYasQDC4ehaADAyMQC/LQB/+NxlAL1qESmKoowlqQhAKVAZ877Kbkt4jDEmCDQDRQNcs2qAawIgIreLyBYR2VJXV5dCd5PjdgkZXjfPbKvmpb0nLReQa2RdQJFZx3NLsoEeQRgtymtbeft4y6h+pqIoE4NxHwQ2xjxkjFlmjFlWUlJy2tfzeV0ca+jgu385YLmA3AmCwMPsAvK6hYw0Nx6XjHoM4N9/v5evPPvWqH6moigTg1QEoBqYEfN+ut2W8BgR8QB5QP0A15w+wDVHhKYOa83fw6faCYTCuHulgQ5/FlBnIES613ItZXjdox4DON7sp7FD1zlWFKUvqQjAZmC+iMwWkTRgNbAm7pg1wK329oeAtaafovrGmONAi4issLN/Pgk8N+jenwadgRDbjjYyPT8j2jYS1UD9gRAZEQFIc9MZGN0YQF1rFy260L2iKAkYUABsn/4dwIvA28CvjTF7ROQbIvIB+7BHgCIRKQfuAqKpoiJyBPgu8CkRqYrJIPoM8BOgHDgEvDA8Q+qfj148kxmF1k2/vTvE0hn50X1WYbjhrQba2R0iIy1GALpHzwXUFQzR3Bmg1R/URW4URelDSrOSjDHPA8/HtX0tZtsP3Jzk3LIk7VuAxal2dLj4rxuXUNviZ/l/vQzAeTECICLRVcGGi85YC8DrHtUYwKm2bsCyaLqC4agrSlEUBSZAEHgkKMnxkePz4BJYXJrba1+ae7gFoOfGm+510zGKFkBda0/dIXUDKYoSjyPrEogIcydl4w+EonMDIvi87mFNA/V391gAmWnuUU0D7SUA/gCTctNH7bMVRRn/OFIAAL5542ISucVHwgVUkuMDLBdQi3/0nsR7C4BOQFMUpTeOFYBzpuUlbB/JGED6KAeB1QWkKEp/ODIG0B8+j3t45wF0x88DGEUBaOupwDEaFoAxho0V9ZpxpCgTBBWAOHxe1/CWggiEyEizvubMtNHNAqpr7SIvwwtA6yi4nnZUNrH6oY1sPtI44p+lKMrpowIQR5rbNbzVQLuHLw306a1VHDzZmvLxh+raWTTVynJq6Rx5C6DeTjttaNdVzxRlIqACEIeVBTQ8AmCM6R0D8LrxB8KEw4N3kRhj+PIzu/jFxqMpHX+qrYvy2jYuX1CM1y2jEnxusxfaaevSNQ8UZSKgAhDHcAaBI9dJj5kJDOAfgoupvTtEIGRSruvz5uEGAFbMKSI33TsqLqDIZ2jJa0WZGKgAxGEJwPA8wUYCvrHzAGLbB0OzncXTlGI2z6aKejLT3CwpzSMn3TMqLqBW2wJoVwtAUSYEKgBx5Gd6qWvpGpKbJp6Ivz/WBRTbPhiaOrp7vQ7EnpoWFpfm4XW7yM3wjo4LyB8RALUAFGUioAIQx+JpebR2BTna0HHa14oKQFpPEBiGaAHYrp+mFF1AzZ0BirLSAGwX0ChYABEBUBeQokwIVADiOHd6PgC7qppO+1qRG316vAtoKBaA7fppTNECaPUHyU23UkAtF9DoBYHVAlCUiYEKQBzzJ2fj87h4q6r5tK8VuSHGpoHC0CyAyJN/qz9IMIX1Clr8AXIzrIneuemj4wLqsQA0BqAoEwEVgDi8bheLpuWy6zQF4NntVax+aCPQ4wKKFGPbOQTroqmz58m/eYCn+UAoTEd3iBzbAsjNGJ0gcFuX1S+1ABRlYqACkIDzpuezu6aZ0BADwZUNHfzLM7uZlpfO/EnZzC7OAmDepGzeMbeIn/z18KCrgjbH+P4HygSKPInnplsWQE66l85AiMAwrnTW3+d2aBaQokwIVAASsKQ0j47uEBV1bUM6/5UDdXQGQjz+txfzl7veSXG2L7rv7985l9rWLl49UDeoa8YGfwfKBIr4+3PtMhARIRhMILi5I8Dr5acG1cdoDECDwIoyIVABSMC5061KoUN1Ax051Y7P42J2UVaffctmFQCw/0TqJR2gt9tnoEygiL8/N+oCsl4HEwh+5LUKPv7IJmpb/YTChuqmzgHP0TRQRZlYqAAkYE5JNllpbt6qHqIA1LczuzgLl0v67MvyeSjNz+BA7eCsi6bObibnWpbEQLOBoy6gjEgWkLdXeyrsqm7GGNhypJHfbq3iyv9ZP6DlEZ0IpkHgKA+/WsGRU+1j3Q1FSYgKQALcLuGc0jw2VtQPKXum4lQ7ZQme/iMsmJw9qKJuYD31R66ZqgsoJz2SBWS9DmYse2paANh8pIHtlU10B8NUNSa3ArqCoWgRPbUALNq6gnzz+bdZs7NmrLuiKAlRAUjC+8+dyr4Trbzr2+t5emtVSqmXAMFQmMqGDmaX9CcAOVTUtad8TbBcQNMLMnHJIFxAGUNzAdW2+qOLyWw50sj+E5YYnGj2Jz0n4v4pyPTS0R0alpnUE51Iuq8KojJeUQFIwicuKWPNHZcyszCTu3+zk6u/+wpPvHlswDpBNU1+AiGT0P8fYf7kHLpDYRb86wvsqRnYzWSMobGjm8IsL4VZPk619V9uOZLy2ZMFNLgg8F776X/57EL21DTz9nHLWjnR0o8A2De5yXaqa8cornswXolkerWqACjjFBWAfjh3ej7P/OM7+NHHLyQvw8uXn3mLy+5bx7df3JfUDXPolOXb788CWFJqBZnDBv646/iA/Tha34E/EGZOSTal+ekDBmRb/AFcAln2gvdRCyAFF1A4bPjN1ipE4P+9ewFh0zNz+WQ/AhARlyl5tgDoTS/6vbXpeszKOEUFYABcLmHl4ik899lLefy25Zw3PY8H1x/isvvW8e+/38PR+t4Bvj/uOk5mmpuzpuQkvebCKTm8/MV3ct70PDbZZZv7IzJx7NzpeZQWZAwoAK3+IDnp3mgQOjvNg0hqLqBfbjrKH3cd54vXLGDFnMJe4+jPBRQRlym2BaCBYHUBKeMfxy4KP1hEhMvnl3D5/BL2nWjhh+sP8fiGo/zsjSNcOreYC2YVcNm8YtbsrOGWZTOimTfJmFuSzSVzi3nktQpr1TB7tnAidlU14/O4WDA5h9L8DNbuq8UYg0jfLCOwbvQRtw9YIpbt86S0LvD2Y01MyU3njqvmA/CxFbO474V9TMr19esCilgHkUlvetPrsQCc7AL6+nO7WVyax83LZox1V5QEqAUwBM6aksv3V5/P6/dcxeeunEdtq58H1pXz4R9vAODWd5SldJ2LZxcSCBnW76/t97i3qppZNC0Xr9tFaX4G/kCY+vbkmUAt/kB0DkCEVOsBHa5vZ06M++rjF89k479czbyS7H5dQDVN1r55k7KBxAIQDhu+99KBlOYUnAmoCwge23CULz29a6y7oSRBLYDTYHJuOnddu5C7rl1IZUMHm480cFFZITMKM1M6/5K5RcyblM2Xnt5FdrqHy+eX9DmmttXPruomVl80E4DSAuva1Y2dvWYYx1LX2hUtBBchN8ObUj2gw6fauX7J1Oh7Ect6mJybzsaK+qTnHW/uJD/Ty7T8DLvffQPV+0608r2XDhI2cNc1Cwbsy0THH3EB6cxomjsC5GX2bxUro49aAMPEjMJMPnjB9JRv/mCVif7FbRczNS+dTzzyJnc9tYOqRmsdgiOn2tl3ooUvPLkDY+DjK2wBsG+wyZ6iD5xsZWdVM5fNK+7VnpPuGdACaGzvpqkjwJzivgHsKXnptPiDSSuZHm/yMzUvg7kl2XjdwtvHW/ocs9vOeHprGEptTwScbgHE1tLaUDG4siLK6KAWwBgzJS+dNXdcxvdfPsijrx/mD28dZ/G0XLYdawKsSWn/deNi5k2ygrGlBZYAvLK/jqvPnoTP0xM7+NJvdrJufy3pXhcfu3hWr8+ZlOPjlQN17K1pYdG03IR9OWwHtGcnEIDIJLR9J1o4f2ZBn/01zX6m5aWT5nExb1IOexMIQCS9dFdVc78xjDOFsYgB7K5u5vXyU/z9O+eO2mcmI3bdiw2H6lm5eGo/RytjgVoA44CMNDf3XHcW6+5+Fx+5aAYd3SH+4Z1z+faHzmXtF9/JLbb7B6zc/px0D09tqWTVD15n69EG6lq72FRRz2+2VlGU5eOL1yykwF4NLMLd1y4kK83Dqgde46u/293rSb6mqZN1+2s5XGcJQFkCAVgxpxCANw4ldgMdb+5kar6VAXT21JzozT6W3XZpjfr2bmr6ySgaDU61dfHy2ydH9DMi33F3MBydJT3SPLOtmv9+Yd+IV35Nhdh/Y9VNY/t7K4lRC2AcUZqfwb+vWtzvMSLCTz91EXtqWvjWn/Zx0w83RPeV5Pj43WcvTZhRVFacxXN3XMoP1pbzi01H+evBOv7xXXOZNymHu3+zk8On2inMSiPN42JGQV83VlG2j7Om5PDGoVN89sp50famjm4efe0wTR0BpuZZ1smiqbk8s62aU21d0ThFKGzYe7yF82fms/1YE7sqm6LurLHgFxuPcv/LB9n7jZXRFduGm9iS3+1dQdI8af0cPTxEgu8N7d3RSXljRez46waYvKiMDSkJgIisBL4PuIGfGGPujdvvA34OXAjUA7cYY47Y+74M3AaEgM8bY160248ArXZ70BizbBjG4wiWlRWyrKyQlYun8FZVM1WNHdQ0+7lifkm/6aSTc9P5jxsWs3LxFL6+Zg///Nu3APC4hFuWzeBgbSufu3o+aZ7EhuE75hbzy01Hae6wVhs73uzn/9aW88SbxwCYak8Ci7iY3qpq5sqzJgFQ1dhBR3eID14wnb01LWw92sh1S8bOJVDb2kXYWDfMkRKAWBdIW1ewj1U2ErTZAee61q4xF4AO2wLweVycSpAUoIw9AwqAiLiBB4BrgCpgs4isMcbsjTnsNqDRGDNPRFYD9wG3iMgiYDVwDjANeElEFhhjIv8zrjTGaHRoiEzOTWfyosH/J790XjEvfuEKymvbOFrfzozCTM6emjguEMsHlk7j8Y1H+OSjm1hWVsgjrx3utT/yRH/BzAKy0tz8ee/JqAAcqbeC2wsmZbN0Rj5vHhl4AtxIErkhtXUFKUqSTXW6dHb3uGHaRikOEJmBPVC5kNEgIoAzCzM52tDhiLjPRCOVGMByoNwYU2GM6QaeBFbFHbMKeMzefhq4WqxfehXwpDGmyxhzGCi3r6eMMW6XsHBKDteeMyWlmz/A0hn5/PBjF3LgZBuPvHaYy+cXs2rpNN78ytU8+qllLJ9txQnSvW6uOnsyf95zIlrw7liDJQCzirK4eE4Ru6ubR+2mmIjIPIrBlMgeLPEWwGjQbq/Gdqqt/4qxo0EkBjCzMJPuYNjRE+LGK6kIQClQGfO+ym5LeIwxJgg0A0UDnGuAP4vIVhG5PdmHi8jtIrJFRLbU1Q1uFS1l+Hn3osm8cOflfOX6s3n4k8v4/urzmZSTzlVnTe71dHf94inUt3fzir3y2bF6a5GcSTk+Lp5dSNjA1qONYzUM6tt6LICRoitWAEYpFbRtXFkAVl8iqdF16gYad4xlFtBlxpgLgOuAz4rIFYkOMsY8ZIxZZoxZVlLSd6KUMvqUFWfxd1fM6dd3ftXZk5hTnMW//X4Pda1dHK3vYEZhJi6XcP7MfFwy1gJgPSGP5I25MxDCbddjGjULwI4BjAefe8QFNlMFYNySigBUA7GFPKbbbQmPEREPkIcVDE56rjEm8loLPIu6hs4ofB439950LjVNfi69dy1/3nuSWfaNIDPNw7xJ2dG00NOhsqGDY3Z8IVX8gVDUHTGSN+bOQIji7LQR/5xY2seVBdDjAoLx0SelN6kIwGZgvojMFpE0rKDumrhj1gC32tsfAtYaY4zdvlpEfCIyG5gPvCkiWSKSAyAiWcC1wO7TH44ynlg+u5AXv3AFk+ylLGNnSS8uzWNHZRNXfWc9v95cmewS/dLZHeLyb63jff/310GdF1tHKZFf+lh9B//z4v5BLdiTrH+RNNjRdwGNgxhARACK1AIYrwwoALZP/w7gReBt4NfGmD0i8g0R+YB92CNAkYiUA3cB99jn7gF+DewF/gR81s4Amgy8JiI7gTeBPxpj/jS8Q1PGA/MmZfMpuzheZkyK6pLSPBrau6moa+f+tQeHdLP94SuHAFKqchpLfcyTaPyNuamjmyu+vY4frCvnwMnBrdscjz8QoijbR5rbxan2kb/5hcIGf8D6HsfD03Znd88aER6XjIs+Kb1JaR6AMeZ54Pm4tq/FbPuBm5Oc+03gm3FtFcB5g+2sMjG59R1ldAXDfDimJPBie1Ecn8dFVWMnP1x/iM9cOS/qMx+I7mCYxzccASDN7RpUimF9zNNxfNXSJ2OskdOdvNQZCDHV62Z6YQaVDYNzUw2F2KJz4+FmG4kBZHrdFGWnqQUwDtFSEMqI43W7+OyV8yjJ6cm3P2daLjnpHu6+diHvXFDCd/5ygB/ZT/QRNh9p4MDJ1oTXXLe/lsaOAJfPL6Y7FKY5xfWOoffNMd43/+qBOjLs4HZtP+WvU6EzYK3zMLMwM5oGO5JExKw420d9e/eYr8vcGQiR5nbhcbsoyEyjcYC1rJXRRwVAGRMy0zxs+PLV/O3ls/nZ31zEhbMKeGF3z/KYwVCYTz36Ju/7v9f45aajWCGlHn63vZribB83XTAdSFx+OhkR/3h+prfXPICO7iBbjjRy04Wlg75mIjq7w6R7bQEYZKB6KEQEoDQ/HWN6ZgWPFZ3dwejM9PxM76BEWhkdVACUMSPb50FEEBGuOmsSu6tbok/de2paaO8OMTnXx1ee3c2D63usA2MMGyrqueqskmj5idqW3jfr7/55P7f9bHPCp+BjDe3kZXiZlOOjravnprTpcAPdoTDXLppCjs9z2i4LfyBEhi0ALf4gzSP8BNxmTwKLrMkw0p83EJ32+AHyM9LGvD9KX1QAlHHBlQutkhHr91sTxzbbpSJ+/feXsGxWAX/c1WMdHKnvoKkjwAUzC5hk17upbe1x12ysqOf+teW8vK+WvySo+HngZBsLJ+eQk+7t5QKKVDC9YFYBJTm+0xIAY4ztAnJFs59G2g0UsQAiRflSWQFuJOkMhKMWQF6Gl6bOsc9MUnqjAqCMC86eaq13/LztBtp8pIGZhZlMzcvgkrlF7DvREr3BbT9mTSA7f2YBk+y4Qqy75id/PczkXB+zijK5/+WDGGOiLiRjDAdOtjJ/cjbZPk+vLKBj9R0UZ6eR7fOctgAEQoZQ2EQtAICjDe1Dvl4qRL6faXZZ7rF2uXR2h6KTBfMzvTSpBTDuUAFQxgUiwqql03j1QB27q5t5o7w+WlvogpkFhI21kAxYC9dn+6zJZFk+D1lp7uh6xcYYdlQ2ctm8Eu64ch57alpY/dBGbnjwDcJhw8mWLlr9QRZOySE73dNrHsDRhvbozbokx9fLqhgsDfZcg9wMb9QCiKy3MFJEsoCiFkAKS4COJJ2BYDT1Ny/TS1cw3KtEtDL2qAAo44YPXlBK2MBHHtpIIBzmH99lrWq1dEY+ANuONRIOG14rP8XSGfnRlNFJuelRC6CqsZNTbd0snZnPDeeXMqMwg02HG9hZ2cSWo43st7OK5k/KISeBBTDLXvmsJMfHkfoO7npqBx1DCKYeiPmcbJ+HRVNzWbe/ttcxlQ0dPLejmg/84DUee+PIoD8jnp4YgGUBtIwDCyA2BgBjb5UovVEBUMYN8ybl8Nkr53JOaS7f/fBS5pZkA1CQlcaCydn8afcJXjlYx+FT7dFMHbBu1tWN1hrJ2yubADh/Rj5et4vv3LyUu65ZQIbXzZqd1ew/Yfn5F0RcQLYF0BUMcbzF38sCAHhmezVbjgy+ZtH+E5YALJxiLeX53nOnsu1YEzVNneyubqapo5ubf7SBO5/cwa6qZl4ahtXJelxA4ycGEHEB5WVYC8KrG2h8oSuCKeOKL73nrITtf3f5HL709C7+6eldlOT4eO+SadF9l88r5jt/OcDOyiZeeOs46V4XZ9k33uWzC1k+u5ADJ1v5/c7jFGR6OXtqLkXZPrLTPXR0h9hZ2UR2ugdjYJZdtiDH1/Nf41BdG1csGFwhwv0nWynJ8VFoLwJz/ZKpfPvF/Xz+ie1sOdrIe5dM5USLn7+/Yg5bjjb2Wj5xqLR3BXGJNQ9AZOwtAH8gFHUB5WdGBEADweMJtQCUCcGN55dy9tRcXAL/deOSXquWffKSMrLS3Nzw4Ou8sPsEH1k+E4+79z/tO6+eT1cwxJH6Dj53lbWk5fLZheT4PKx64HU+/bPNQI8A3HjBdL5107lk+zwcrG0jHDZsOFSf8lq7B062snByTvT97OIsPn/VvGgc4897TwDW6m5T8tKjMYPT4Xizn4LMNNwuITd9bPPuf7+zhsOn2qMuoKgFoC6gcYUKgDIh8LhdPPfZS3n9n6/imkWTe+3Ly/Tylfcu4salpTzxdyv4+vvP6XP+/Mk5fO+WpXxk+UxWnjMFsJa4fOPLV/HV9y0iGDKke11Rt1O2z8OHL5rBwik5lNe28fS2Kj7y8EY++vBGWv0BjDGs3XcyYQ2jcNjKNFoQIwAAd127kM3/+m5uvnA6gZCVlTS7OJPCzLReBeqGysaKepaVFQCQm+EZdI2k4SIUNnzuie0AzJ1kxVQiFsBYiVLjMHy/ZyLqAlImDMnWKgb46MUz+ejFM/s9f+Xiqaxc3Hsd4px0L7ddNptbL5lFc2eA/Mze6/bOn5TNn/ee5GevH2Fyro/NRxr58SsVTMlL519/t5t7P7iE1ct7f25lYwf+QJiFU7L79CEvwxuNC7jEqpBamJVGc2eAYCjcx3JJlcqGDqoaO/nby2ZHP2esbrbHm614zH+sOodPXFIW7Q+MzeS0jRX1fOwnm1h/97t6VaRV1AJQFMCyMBKtDTxvUjYN7d3sPd7CnVcv4L1LpvLT1w/z6OvWeshVdvA5ln3RAHDipTYjlsG0/Ax8HqtQGnBatXI2VNQDcMncYgBy071jFgOIlL2YU9IjgNk+D26XjMlksP0nWgmFzajUY5poqAAoSj+smFNEZpqbW5bN4KYLS7nr2gWkeVxU2Dn95bV9S0YfOBFJAe1rAUCPAMwuttwjkUDx6cQBth9rJD/Ty4LJ1meOpQUQudHOjHnaFhHyM8ZmMtgJe45Iowag+6AuIEXph8Wleez9xsro+7kl2bzyT1fy6oE6nt1WzYHavtVK959sZUZhBlm+xP+9Juf6mJKbzqJploVQmHn6AnDwZBsLJuVES2LnpnvHLA30aEMHHpdE01EjFGalnXaBvaFwotkWAI0D9EEtAEUZJLnpXt537jQWTcvlyKl2/IEQ6/bXRm+4VgZQYvcPWE/Dv//cZfy/dy8AoDA7dQF4o/wUv99Z06vNGEN5XRtzYyyO3AzPmFoA0wsy+qztMH9ydtLy3iNJJCYxFBebPxDqU4k2FZo6umkd43kYqaACoChDZP7kHMIGfvxKBX/z0818+Ecb2FvTQkVde8IAcCwlOb7oJKkeF9DAT8f/+9IB/vv5t3u11bd309QRYF6MAEzOTccfCI/JIizH6juYac+ojuWsKbkca+joswjPSHPSrhQ7WAurrSvI8m++xHM7agY+OI5bf7qZrzw7/le5VQFQlCFyrr2q2fdfPsDkXB+VDR1cf/9fcYnw7rMnD3B2DwVRF1D/T4zGGPYdb+VEi5/uYE/66UF76crYmMMFs6x00C1HGkbV9dHRHeTwqXZmFmb02bdwSg7GMKpWgDEmagEMdhLagZOttPiD0bkbqeIPhNhd3czbx1sGdd5YoAKgKEOkrDiL+25agojwL9efzR8/fzk3LJ3GY59ezvkzC1K+jtftIjfd068F4A+EOFjbRmtXkLDpcWsAlNdZAhBrASyelofP4+Irv9vNZfetPe14wMaK1CbB3f9yOW1dQW5YWtpnX2R2dqRMxmjQ0hmMrpPcMEgX0EFbqAabPbTPzjo62tAx5quyDYQKgKKcBrdcNJNdX7+WVUtLKSvO4nurz+eSuUWDvs6MwkzW7a9LeqO+88ntXPu/r0bfVzb0CMC+4y1kpbmji+OANWdi6Yx8Gtq7ae8OscVeX2EobD/WyOqHNvaJPcTT1hXk0dcO88ELSllWVthn/4yCTDLT3NE02dHgeEvP9zRYCyBiWVU1Dk4AdldbFkN3MMy+E63jugCeCoCinCbJsn0Gw7994Byqmzq584nt7D/R2stt0+oPsHZfXCVR+6ZkjGHdvlreMa84mgEU4ZK5RbgEPC5hY8XAAhAOG149UBcNenYFQzy+8Si/3VYFwO7q/l0aGw7V0x0K8yF7mc54XC5hcWkebx4euhgNlohQzirKHHQM4ICd4lvZ0DGoQPCemp7v6fr7/8qdT24f1OeOJioAijIOuKiskP9YtZh1++t4z/de5ervvsKfdh/nWH0HL+45GS0dAdYNvdJ2S7xV3UxNs5/32OUtYrn9ijk8f+flXDCrgA2H6gfsw5ObK/nko2/y4h6rMukTm47x1d/t5hcbjwEM6NN+9UAdmWluLixL7v666qxJ7D3eQk1T3wl0w00gFOZ7Lx2gONvHitlFg56DUH6yFRFo7w6lLB4Pri9nzY7qXnMg3jzckLRkSKL20UQFQFHGCR+9eCY/+Oj5fO19i8hN9/APv9jGFd9ex92/2UlBppeXv/hO/vSFy5mWn0FlYyfhsOGnrx/B7RLeffakPtfLTPNw1pRc3jG3iLeqm7nkv1/mB2sP9vFLVzZY6x48sK4cgGe3V/HMtip+/GoFPrv8hs/j4u0TLUmfhMNhwysH6rhkThE+jzvpGCP9fHB9ecJJdMPJs9uq2VPTwn/ecA7TCzJo6wr2Cp73x++2V1PT7I+uRXHd9//KawdP9XvOqbYuvvPnAyyalst3P3xetL2jO8SBk33H+i/PvsWND75BZ3eI+rbRz9YCnQimKOOK951rlbn+6MUz2XKkkRMtfg6ebOWsqTnRQnXTCzLYW9PM55/czh92Hecf3zW3Tw2jWD592WzyMrys21/H//z5AAdr2/C6Xdx59XzeOHSKX71ZyU57HYU5xVm8uOckL+45iQg8cusy3j5uBTW/+5cDPPRqBauXz4zW9onwm62VHGvo4K5rFvQ7vrkl2cwpyeIXG4/x6y1VfOfm83j/edP6PWeoPLO9ijnFWbznnCmcarOsmKaO7ug60snYdqyRLzy1gwtnFfDFaxbw0Z9sora1i5+9cYTL5hcnPe8PO2sIhQ3fvHFJn0KA2441Rif+AdS1dvHbbVUEQoYbHnidVn+Av/7zVX3mTow0KgCKMg5J97qT3mxuWFrKPc/s4lBdO1++7ixuv2JOv9fKTffyN5fO5lPvKOMLT+2I5rWv2VFDt+2C+M7N5zF3UjbGGG758Ua+9J6FfGzFTDLTPFx11uSo3/6/X9jHy2/Xsur8aayYU0Rehpffba/mey8dZHlZIauW9n8zFxF+cdvF1DR18q0/7ecLT+3gjUP1LJ2Rx4eXzegTxxgKYbvuz8aKBu66ZgEiEk21/cwvt/E/N59HWXHveQrGGDZU1LNoai7ff+kgBZlefv7p5cR257XyOmuVs7S+Fo4/EOLJzZWcPTU3evP/xW0X4/O6+IfHt/LMtiqm5adz4axCfvr6YX6/s4ZAyJDmdkVXqXvzcMOQEghOBxnKLLexYtmyZWbLli1j3Q1FGXN2VzfT3Bng0nnJn0gT0RUMseNYEwdOtnLvC/u496ZzWTglp9cTqz/Qs5h7hO5gmP96/m0y09w8uP5Qn+teOq+Ib33oPErz++b/J6OtK8inf7aZ7ccaCYQMRVnWWgbnzchnUo6PDK+bJdPzaO4McOGsAtK9bgQ4VNfO28dbWFyay8GTbcwqyiLNI1Q1dlJR184vNx0FwCXCS3e9kxmFmdS3dfHN59/m5bdryc/0smJ2ERfPKeTc6fms319LZUMHj204iggYA/+0ciGfeZe1bsTJFj8HTrbyiUfe5FPvKOP2K+b0KnOxdt9JHnq1go0VDfzo4xeycnHveMy3X9zHw68ejootWCmxF5UV0hkIseFQPQ3t3XzwglK+eeOSlL+/wSAiW40xy/q0qwAoijMZavnpyoYOuoJh1u47iUuEFXOKOGda7pCf3kNhw8/eOMKe6mZEhI0V9TR3BvAHQgSHkEf/3nOnMjU3nY9cPDPqNouwsaKeu3+zk7auYJ+g8HvPncr0ggwWTc3l/edOwxXjjgmEwlz//b9ysLaNvAwvt76jDK9L2HeylT/uOk5xdhpfePcCPr5iVsI++QMhth1rZFNFAzMKM7npglJEhO5gmO5QmH955i3W7Kzh4tmFfPPGJdE5Hb/bXs1TmyvJSffwvdVLyUwbmtNGBUBRlAmDMYbqpk5OtnRRlJXG3uMtdAVDBIIGBC6cVcDhunbOn5lPTZOfVn+A0oIMWjqDLJmeN+D1w2HDrupmthxp4IoFJbR0Blg6I39AQayoa+Off7uLLUcbMQYKMr186MLp/NPKs/AOcS0HsNZJ+MWmozz0agXNnQFmFmYSDIWpafYzpziLNI+LP37+8iHHCFQAFEVRhomO7iBul/Sb8TQUalv8/HpLJftPtuHzuCgryuT2K+b2uxhSKiQTAA0CK4qiDJKhumIGYlJuOndcNX9Erp0InQegKIriUFISABFZKSL7RaRcRO5JsN8nIk/Z+zeJSFnMvi/b7ftF5D2pXlNRFEUZWQYUABFxAw8A1wGLgI+IyKK4w24DGo0x84D/Be6zz10ErAbOAVYCD4qIO8VrKoqiKCNIKhbAcqDcGFNhjOkGngRWxR2zCnjM3n4auFqsnLBVwJPGmC5jzGGg3L5eKtdUFEVRRpBUBKAUqIx5X2W3JTzGGBMEmoGifs5N5ZoAiMjtIrJFRLbU1dWl0F1FURQlFcZ9ENgY85AxZpkxZllJSclYd0dRFOWMIRUBqAZmxLyfbrclPEZEPEAeUN/PualcU1EURRlBUhGAzcB8EZktImlYQd01ccesAW61tz8ErDXWDLM1wGo7S2g2MB94M8VrKoqiKCPIgLMZjDFBEbkDeBFwA48aY/aIyDeALcaYNcAjwOMiUg40YN3QsY/7NbAXCAKfNcaEABJdc6C+bN269ZSIHB3KQIFioP+C3hMHHcv4RMcy/jhTxgGnN5aERYomVCmI00FEtiSaCj0R0bGMT3Qs448zZRwwMmMZ90FgRVEUZWRQAVAURXEoThKAh8a6A8OIjmV8omMZf5wp44ARGItjYgCKoihKb5xkASiKoigxqAAoiqI4lDNeACZ62WkROSIib4nIDhHZYrcVishfROSg/Vow1v1MhIg8KiK1IrI7pi1h38Xifvt32iUiF4xdz/uSZCz/JiLV9m+zQ0Suj9mXsAz6eEBEZojIOhHZKyJ7ROROu33C/Tb9jGXC/TYiki4ib4rITnss/263z7bL7JfbZffT7PakZfhTxhhzxv5hTTI7BMwB0oCdwKKx7tcgx3AEKI5r+xZwj719D3DfWPczSd+vAC4Adg/Ud+B64AVAgBXAprHufwpj+Tfg7gTHLrL/rfmA2fa/QfdYjyGmf1OBC+ztHOCA3ecJ99v0M5YJ99vY32+2ve0FNtnf96+B1Xb7j4B/tLc/A/zI3l4NPDXYzzzTLYAztex0bPntx4Abxq4ryTHGvIo1MzyWZH1fBfzcWGwE8kVk6qh0NAWSjCUZycqgjwuMMceNMdvs7VbgbaxqvBPut+lnLMkYt7+N/f222W+99p8BrsIqsw99f5dEZfhT5kwXgJTLTo9jDPBnEdkqIrfbbZONMcft7RPA5LHp2pBI1veJ+lvdYbtFHo1xxU2Ysdhug/OxnjYn9G8TNxaYgL+NWAtm7QBqgb9gWShNxiqzD737m6wMf8qc6QJwJnCZMeYCrNXTPisiV8TuNJb9NyFzeSdy321+CMwFlgLHge+MaW8GiYhkA78FvmCMaYndN9F+mwRjmZC/jTEmZIxZilUheTlw1kh+3pkuABO+7LQxptp+rQWexfpHcTJigtuvtWPXw0GTrO8T7rcyxpy0/8OGgYfpcSWM+7GIiBfrhvlLY8wzdvOE/G0SjWUi/zYAxpgmYB1wCZbLLVK4M7a/ycrwp8yZLgATuuy0iGSJSE5kG7gW2E3v8tu3As+NTQ+HRLK+rwE+aWecrACaY9wR45I4P/iNWL8NJC+DPi6w/cSPAG8bY74bs2vC/TbJxjIRfxsRKRGRfHs7A7gGK6axDqvMPvT9XRKV4U+dsY58j/QfVgbDASxf2lfGuj+D7PscrIyFncCeSP+x/HwvAweBl4DCse5rkv4/gWV+B7B8l7cl6ztWBsQD9u/0FrBsrPufwlget/u6y/7PODXm+K/YY9kPXDfW/Y8by2VY7p1dwA777/qJ+Nv0M5YJ99sA5wLb7T7vBr5mt8/BEqly4DeAz25Pt9+X2/vnDPYztRSEoiiKQznTXUCKoihKElQAFEVRHIoKgKIoikNRAVAURXEoKgCKoigORQVAURTFoagAKIqiOJT/D11B+/BH8H80AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "pyplot.plot(history_lstm.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19e1e31450d845b23a36a86329d833b0ddee3a7e54ea63e3a0ae65e84a65d7ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('Innovation_Project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
