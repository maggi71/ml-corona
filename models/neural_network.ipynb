{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendung und Vergleich von Machine Learning und Deep Learning Algorithmen zur Vorhersage von COVID-19 Kennzahlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronale Netze\n",
    "Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten, MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from disk\n",
    "# X_train = np.load('../preprocessing/X_train.npy')\n",
    "# X_test = np.load('../preprocessing/X_test.npy')\n",
    "# y_train = np.load('../preprocessing/y_train.npy')\n",
    "# y_test = np.load('../preprocessing/y_test.npy')\n",
    "\n",
    "data = np.load('../preprocessing/dataset.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move first columns (= cases) to the end of the array\n",
    "permutations = [1,2,3,4,5,6,7,8,9,10,0]\n",
    "data = data[:, permutations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform data into sequences\n",
    "def transform_to_sequences(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t# n_vars corresponds to the number of features\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t\n",
    "\t# input sequence (t-n, ..., t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t\t\n",
    "\t# forecast sequence(t, t+1, ..., t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t\t\n",
    "\t# put all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t\n",
    "\tif dropnan:\n",
    "\t\t# drop all rows that contains Nan values (1st row)\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 11)\n",
      "(199, 11)\n"
     ]
    }
   ],
   "source": [
    "# Split data in training and test set\n",
    "num_datapoints = data.shape[0]\n",
    "num_training = int(num_datapoints*0.7)\n",
    "\n",
    "train, test = data[:num_training], data[num_training:]\n",
    "\n",
    "# Verify the shapes of train and test\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the datasets using RobutScaler (as this scaler scales the data according to the quantile range (default: Inter Quartile Range IQR))\n",
    "# TODO: select good scaler\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data into sequences\n",
    "train_transformed = transform_to_sequences(train_scaled, 14, 1)\n",
    "test_transformed = transform_to_sequences(test_scaled, 14, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 165)\n",
      "(185, 165)\n"
     ]
    }
   ],
   "source": [
    "# Verify the shapes of train_transformed and test_transformed\n",
    "print(train_transformed.shape)\n",
    "print(test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in input X and output y\n",
    "n_input_timestamps = 14\n",
    "n_features_per_timestamp = 11\n",
    "n_input_features = n_input_timestamps * n_features_per_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 154)\n",
      "(448, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train_transformed.values[:, :n_input_features], train_transformed.values[:, n_input_features:]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272483</td>\n",
       "      <td>0.115409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299731</td>\n",
       "      <td>0.126950</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.019874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326979</td>\n",
       "      <td>0.138491</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.031571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354228</td>\n",
       "      <td>0.150032</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.033853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381476</td>\n",
       "      <td>0.161573</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.040890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6         7         8         9         10\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.272483  0.115409  0.000000  0.018068\n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.299731  0.126950  0.018519  0.019874\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.326979  0.138491  0.027778  0.031571\n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.354228  0.150032  0.037037  0.033853\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.381476  0.161573  0.027778  0.040890"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 0 to 9 as we just want to predict feature #10 (= cases)\n",
    "y_train = y_train[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185, 154)\n",
      "(185, 11)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_transformed.values[:, :n_input_features], test_transformed.values[:, n_input_features:]\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.867587</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.733161</td>\n",
       "      <td>0.474988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.435694</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>0.133835</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.850201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859001</td>\n",
       "      <td>0.599870</td>\n",
       "      <td>0.311022</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.592891</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.129780</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.013778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884554</td>\n",
       "      <td>0.493402</td>\n",
       "      <td>0.183680</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.490748</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.122248</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.010452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.805378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939504</td>\n",
       "      <td>0.270029</td>\n",
       "      <td>0.202176</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.263427</td>\n",
       "      <td>0.203448</td>\n",
       "      <td>0.103708</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.007760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.007126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.867587  0.000014  0.733161  0.474988  1.000000  0.000371  0.435694   \n",
       "1  0.850201  0.000000  0.859001  0.599870  0.311022  0.000604  0.592891   \n",
       "2  0.806728  0.000000  0.884554  0.493402  0.183680  0.000868  0.490748   \n",
       "3  0.805378  0.000000  0.939504  0.270029  0.202176  0.001949  0.263427   \n",
       "4  0.755921  0.000000  0.929662  1.000000  0.247540  0.002303  1.000000   \n",
       "\n",
       "         7         8        9         10  \n",
       "0  0.248276  0.133835  0.00000  0.021300  \n",
       "1  0.241379  0.129780  0.03125  0.013778  \n",
       "2  0.206897  0.122248  0.12500  0.010452  \n",
       "3  0.203448  0.103708  0.09375  0.007760  \n",
       "4  0.200000  0.095017  0.09375  0.007126  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 0 to 9 as we just want to predict feature #10 (= cases)\n",
    "y_test = y_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to fit into the LSTM model (dimension must be [samples, time steps, features])\n",
    "X_train_lstm = X_train.reshape((X_train.shape[0], n_input_timestamps, n_features_per_timestamp))\n",
    "y_train_lstm = y_train.reshape((y_train.shape[0], 1))\n",
    "\n",
    "X_test_lstm = X_test.reshape((X_test.shape[0], n_input_timestamps, n_features_per_timestamp))\n",
    "y_test_lstm = y_test.reshape((y_test.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neuronal Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network (mit LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(100, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "model_lstm.add(Dense(1, activation='relu'))\n",
    "\n",
    "model_lstm.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_13 (LSTM)              (None, 100)               44800     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,901\n",
      "Trainable params: 44,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training der Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training des CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training des LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 2s 5ms/step - loss: 0.0315\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0262\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0203\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0120\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0115\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0077\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0089\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0068\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0067\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0068\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0070\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0072\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0070\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0081\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0117\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0079\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0071\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0076\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0067\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0058\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.0058\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0057\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0076\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0057\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0059\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0055\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0060\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0058\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0066\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0054\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0105\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0070\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0066\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0064\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0056\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0073\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0096\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0070\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0082\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0068\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0074\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0073\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0050\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0049\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0047\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0048\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0055\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0065\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0047\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0041\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0051\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0077\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0048\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0047\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0041\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0038\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0038\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0030\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0032\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0035\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0034\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0037\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0032\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0028\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0023\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0027\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0022\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM model\n",
    "history_lstm = model_lstm.fit(X_train_lstm, y_train_lstm, epochs=300, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "pyplot.plot(history_lstm.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19e1e31450d845b23a36a86329d833b0ddee3a7e54ea63e3a0ae65e84a65d7ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('Innovation_Project': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
